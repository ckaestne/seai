<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no" />

    <title>17-445: From Models to AI-Enabled Systems</title>
    <link rel="stylesheet" href="./../css/reveal.css" />
    <link rel="stylesheet" href="./../css/theme/white.css" id="theme" />
    <link rel="stylesheet" href="./../css/highlight/zenburn.css" />
    <link rel="stylesheet" href="./../css/print/paper.css" type="text/css" media="print" />
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.5.0/css/font-awesome.min.css">
     <script src="./../rplugin/spreadsheet/ruleJS.all.full.min.js"></script>
   <link rel="stylesheet" href="./../rplugin/spreadsheet/spreadsheet.css">
    <link rel="stylesheet" href="./../_assets/_assets/cmu.css" />

  </head>
  <body>
    <div class="reveal">
      <div class="slides"><div id="footer">17-445 Machine Learning in Production / AI Engineering, Eunsuk Kang & Christian Kaestner</div><section  data-markdown><script type="text/template">  

# From Models to Production Systems (Systems Thinking)

Christian Kaestner

<!-- references -->

* Hulten, Geoff. "Building Intelligent Systems: A Guide to Machine Learning Engineering." (2018), Chapters 5, 7, and 8.
</script></section><section  data-markdown><script type="text/template">
# Learning goals

* Explain the consequences of the shift from deductive to inductive reasoning for abstraction and composition
* Explain how machine learning fits into the larger picture of building and maintaining production systems
* Explain the modularity implications of having machine-learning components without specifications
* Describe the typical components relating to AI in an AI-enabled system and typical design decisions to be made








</script></section><section ><section data-markdown><script type="text/template"># ML Models as Part of a System

</script></section><section data-markdown><script type="text/template">## Example: Image Captioning Problem

![Image captioning one step](imgcaptioning.png)
</script></section><section data-markdown><script type="text/template">## Example: Image Captioning Problem

![Image captioning with ML](imgcaptioningml.png)

</script></section><section data-markdown><script type="text/template">## Why do we care about image captioning?

![Image captioning one step](imgcaptioning.png)
</script></section><section data-markdown><script type="text/template">## Machine learning as (small) component in a system

<!-- colstart -->
![Tax system architecture with an ML component](tax-with-ml.png)
<!-- col -->
[![Audit risk meter](audit-risk-meter.png)](https://ttlc.intuit.com/community/choosing-a-product/help/about-the-audit-risk-meter/00/25924)
<!-- colend -->

<aside class="notes"><p>Traditional non-ML tax software, with an added ML component for audit risk estimation</p>
</aside></script></section><section data-markdown><script type="text/template">## Machine learning as (core) component in a system

<!-- colstart -->
![Transcription system architecture](transcriptionarchitecture.png)
<!-- col -->
![Screenshot of Temi transcription service](temi.png)
<!-- colend -->

<aside class="notes"><p>Transcription service, where interface is all built around an ML component</p>
</aside></script></section><section data-markdown><script type="text/template">## Many more examples:

* Product recommendations on Amazon
* Surge price calculation for Uber
* Inventory planning in Walmart
* Search for new oil fields by Shell
* Adaptive cruise control in a car
* Smart app suggestion in Android
* Fashion trends prediction with social media data
* Suggesting whom to talk to in a presidential campain
* Tracking and predicting infections in a pandemic
* Adaptively reacting to network issues by a cell phone provider
* Matching players in a computer game by skill
* ...
* 
* Some for end users, some for employees, some for expert users
* Big and small components of a larger system

</script></section><section data-markdown><script type="text/template">## Model vs System Goal?

![Image captioning one step](imgcaptioning.png)
</script></section><section data-markdown><script type="text/template">## Model vs System Goal?

![Transcription system architecture](transcriptionarchitecture.png)

</script></section><section data-markdown><script type="text/template">## More Accurate Predictions may not be THAT Important

* "Good enough" may be good enough
* Prediction critical for system success or just an gimmick?
* Better predictions may come at excessive costs 
    - need way more data, much longer training times
    - privacy concerns
* Better user interface ("experience") may mitigate many problems
    - e.g. explain decisions to users
* Use only high-confidence predictions?

</script></section><section data-markdown><script type="text/template">
## Beyond Software: Impact on Our Society

![Predictive policing](predictive-policing.png)


</script></section><section data-markdown><script type="text/template">## Machine learning that matters

* 2012 essay lamenting focus on algorithmic improvements and benchmarks in ML
  - focus on standard benchmark sets, not engaging with problem: Iris classification, digit recognition, ...
  - focus on abstract metrics, not measuring real-world impact: accuracy, ROC
  - distant from real-world concerns
  - lack of follow-through, no deployment, no impact
* Failure to *reproduce* and *productionize* paper contributions common
* Ignoring design choices in how to collect data, what problem to solve, how to design human-AI interface, measuring impact, ...
*
* Should focus on making impact -- requires building systems


<!-- references -->

Wagstaff, Kiri. "Machine learning that matters." In Proceedings of the 29 th International Conference on Machine Learning, (2012).



</script></section><section data-markdown><script type="text/template">## On Terminology

* There is no standard term for referring to building systems with AI components
* "Production ML Systems", "AI-Enabled Systems", "ML-Enabled Systems" or "ML-Infused Systems"; SE4AI, SE4ML
* sometimes "AI Engineering" (but often used with a data-science focus)
* sometimes "ML Systems Engineering" (but often this refers to building distributed and scalable ML learning and data storage platforms)
* "AIOps" ~ using AI to make automated decisions in operations; "DataOps" ~ use of agile methods and automation in business data analytics; "MLOps" ~ technical infrastructure for operating AI-based products and on deploying updates
























</script></section></section><section ><section data-markdown><script type="text/template"># Systems Thinking


</script></section><section data-markdown><script type="text/template">## Repeat: Machine learning as component in a system

![Transcription system architecture](transcriptionarchitecture.png)

</script></section><section data-markdown><script type="text/template">## The System Interacts with Users

[![Audit risk meter](audit-risk-meter.png)](https://ttlc.intuit.com/community/choosing-a-product/help/about-the-audit-risk-meter/00/25924)

<aside class="notes"><p>Audit risk meter from Turbo-Tax</p>
</aside></script></section><section data-markdown><script type="text/template">## The System Interacts with the World

![Smart Toaster](toaster.jpg)

</script></section><section data-markdown><script type="text/template">## The System Interacts with the World

![Crime Map](crime-map.jpg)

* Model: Use historical data to predict crime rates by neighborhoods
* Used for predictive policing: Decide where to allocate police patrol
</script></section><section data-markdown><script type="text/template">## System <-> World = Feedback Loops?

![Crime Map](crime-map.jpg)


```mermaid
graph LR;
h[Historic bias] --> Data
Data -->|ML| Model
Model --> Predictions
Predictions -->|influence| Data
```

</script></section><section data-markdown><script type="text/template">## ML Predictions have Consequences

* Assistance, productivity, creativity
* Manipulation, polarization, discrimination
* Feedback loops

</script></section><section data-markdown><script type="text/template">## Safety is a System Property

* Code/models are not unsafe, cannot harm people
* Systems can interact with the environment in ways that are unsafe

![Smart Toaster](toaster.jpg)
</script></section><section data-markdown><script type="text/template">## Safety Assurance in the Model/outside the Model

> Goal: Ensure smart toaster does not burn the kitchen

<!-- discussion -->
</script></section><section data-markdown><script type="text/template">## Safety Assurance in the Model/outside the Model

<!-- colstart -->
* In the model
  - Ensure maximum toasting time
  - Use heat sensor and past outputs for prediction
  - Hard to make guarantees
* Outside the model (e.g., "guardrails")
  - Simple code check for max toasting time
  - Non-ML rule to shut down if too hot
  - Hardware solution: thermal fuse

<!-- col -->

![Thermal fuse](thermalfuse.png)
(Image CC BY-SA 4.0, C J Cowie)
<!-- colend -->
</script></section><section data-markdown><script type="text/template">## Model vs System Properties

* Similar to safety, many other qualities should be discussed at model **and** system level
  - Security
  - Privacy
  - Transparency, accountability
  - Maintainability
  - Scalability, energy consumption
  - Impact on system goals
  - ...



</script></section><section data-markdown><script type="text/template">## Thinking about Systems

* Holistic approach, looking at the larger picture, involving all stakeholders
* Looking at relationships and interactions among components and environments
    - Everything is interconnected
    - Combining parts creates something new with emergent behavior
    - Understand dynamics, be aware of feedback loops, actions have effects
* Understand how humans interact with the system

> A system is a set of inter-related components that work together in a particular environment to perform whatever functions are required to achieve the system's objective -- Donella Meadows

<!-- references -->
Leyla Acaroglu. "[Tools for Systems Thinkers: The 6 Fundamental Concepts of Systems Thinking](https://medium.com/disruptive-design/tools-for-systems-thinkers-the-6-fundamental-concepts-of-systems-thinking-379cdac3dc6a)." Blogpost 2017
</script></section><section data-markdown><script type="text/template">## System-Level Challenges for AI-Enabled Systems

* Getting and updating data, concept drift, changing requirements
* Handling massive amounts of data
* Interactions with the real world, feedback loops
* Lack of modularity of AI components, lack of specifications, nonlocal effects
* Deployment and maintenance
* Versioning, debugging and incremental improvement
* Keeping training and operating cost manageable
* Interdisciplinary teams
* Setting system goals, balancing stakeholders and requirements
* ...









</script></section></section><section ><section data-markdown><script type="text/template"># Designing Intelligent Experiences

(Human-AI Interaction)
</script></section><section data-markdown><script type="text/template">## AI predictions should influence the world

* Smart toaster
* Automated slide design
* Product or music recommendations
* Feed curation in social media or news
* Recidivism prediction
* Health monitoring
* Transcription services
* Image search engine
* Self-driving cars
* Smart home
*
* Interact with the world through actuators (smart devices) or by influencing people


</script></section><section data-markdown><script type="text/template">## Designing Intelligent Experiences

* How to use the output of a model's prediction (for a objective)?
* Design considerations:
    - How to present prediction to a user? Suggestions or automatically take actions?
    - How to effectively influence the user's behavior toward the system's goal?
    - How to minimize the consequences of flawed predictions?
    - How to collect data to continue to learn from users and mistakes?
* Balancing at least three **system-level** outcomes:
    - Achieving objectives
    - Protection from mistakes
    - Collecting data for training

</script></section><section data-markdown><script type="text/template">## Presenting Intelligence

* Automate: Take action on user's behalf

* Prompt: Ask the user if an action should be taken

* Organize: Display a set of items in an order

* Annotate: Add information to a display

* Hybrids of these

</script></section><section data-markdown><script type="text/template">## Factors to Consider


* **Forcefulness**: How strongly to encourage taking an action (or even automate it)?
* **Frequency**: How often to interact with the user?
* **Value**: How much does a user (think to) benefit from the prediction?
* **Cost**: What is the damage of a wrong prediction?




</script></section><section data-markdown><script type="text/template">## Breakout Discussion: Experience Design


<!-- colstart -->

Fall detection for elderly people:

![Smart watch](smartwatch.jpg)


<!-- col -->

Safe browsing: Blocking malicious web pages

![Safe browsing warning](warning.png)

<!-- colend -->


* How do we present the intelligence to the user?
* Consider system goals, forcefulness, frequency, value of correct and cost of wrong predictions

<aside class="notes"><p>Devices for older adults to detect falls and alert caretaker or emergency responders automatically or after interaction. Uses various inputs to detect falls.
Read more: <a href="https://www.mobihealthnews.com/content/how-fall-detection-moving-beyond-pendant">How fall detection is moving beyond the pendant</a>, MobiHealthNews, 2019</p>
</aside></script></section><section data-markdown><script type="text/template">## Collecting Feedback

![Safe Browsing Feedback](safe-browsing-feedback.png)





</script></section></section><section ><section data-markdown><script type="text/template">
# Operating Production ML Systems

(deployment, updates)
</script></section><section data-markdown><script type="text/template">## Things change...


<!-- colstart -->

* Newer better models released
  - Better model architectures
  - More training data
* Goals and scope change
  - More domains supported
  - Better recognition of dialects
* Model training due to drift
  - New terms (jargon) emerge in domain
  - Increased adoption in region with dialect
* Online experimentation


<!-- col -->

![Architecture diagram of transcription service; many components, not just ML](transcriptionarchitecture.png)


<!-- colend --></script></section><section data-markdown><script type="text/template">## Things change...


<!-- colstart -->

<!-- discussion -->

<!-- col -->

*Reasons for change in audit risk prediction?*
![Audit prediction](audit-risk-meter.png)


<!-- colend -->
</script></section><section data-markdown><script type="text/template">## Monitoring in Production

Design for telemetry

<!-- colstart -->
![Safe Browsing Feedback](safe-browsing-feedback.png)
<!-- col -->
![Safe Browsing Statistics](safe-browsing-stats.png)
<!-- colend -->

</script></section><section data-markdown><script type="text/template">## Monitoring in Production


<!-- colstart -->

<!-- discussion -->

<!-- col -->

*What and how to monitor in audit risk prediction?*
![Audit prediction](audit-risk-meter.png)


<!-- colend -->
</script></section><section data-markdown><script type="text/template">## Pipeline Thinking


![Pipeline](pipeline.png)

<!-- references -->

* Graphic: Amershi et al. "[Software engineering for machine learning: A case study](https://www.microsoft.com/en-us/research/uploads/prod/2019/03/amershi-icse-2019_Software_Engineering_for_Machine_Learning.pdf)." In Proc ICSE-SEIP, 2019. 

</script></section><section data-markdown><script type="text/template">## Design with Pipeline and Monitoring in Mind

![Architecture diagram of transcription service; many components, not just ML](transcriptionarchitecture2.png)
</script></section><section data-markdown><script type="text/template">## Shifting from Models to Pipelines is Challenging

Across interviews with enterprise ML teams:

* Data scientists often focus on modeling in local environment, model-centric workflow
* Rarely robust infrastructure, often monolithic and tangled
* Challenges in deploying systems and integration with monitoring, streams etc
* 
* Shifting to pipeline-centric workflow challenging
* Requires writing robust programs, slower, less exploratory
* Standardized, modular infrastructure 
* 
* Big conceptual leap, major hurdle to adoption

<!-- references -->

O'Leary, Katie, and Makoto Uchida. "[Common problems with Creating Machine Learning Pipelines from Existing Code](https://research.google/pubs/pub48984.pdf)." Proc. Third Conference on Machine Learning and Systems (MLSys) (2020).








</script></section></section><section ><section data-markdown><script type="text/template"># Traditional vs AI-based Software Systems

(deductive vs inductive reasoning)
</script></section><section data-markdown><script type="text/template">## Complexity in Engineered Systems

![Airplane](airplane.jpg)

* Automobile: ~30,000 parts; Airplane: ~3,000,000 parts
* MS Office: ~ 40,000,000 LOCs; Debian: ~ 400,000,000 LOCs
* How do we build such complex systems?
</script></section><section data-markdown><script type="text/template">## Managing Complexity in Software

* **Abstraction**: Hide details & focus on high-level behaviors
* **Reuse**: Package into reusable libraries & APIs with well-defined _contracts_
* **Composition**: Build large components out of smaller ones

```java
/**
 * compute deductions based on provided adjusted 
 * gross income and expenses in customer data.
 *
 * see tax code 26 U.S. Code A.1.B, PART VI
 *
 * Adjusted gross income must be positive; 
 * returned deductions are not negative.
 */
float computeDeductions(float agi, Expenses expenses) {
  ...
}
```

</script></section><section data-markdown><script type="text/template">## Divide and Conquer

* Human cognitive ability is limited
* Decomposition of software necessary to handle complexity
* Allows division of labor
* Deductive reasoning, using logic

![Tax computation system with three components](tax-decomposition.png)
<!-- .element: class="stretch" -->

</script></section><section data-markdown><script type="text/template">## Debugging and Assigning Blame

* Each component has own specification
* For each input, specification indicates whether output correct

```java
/**
 * compute deductions based on provided adjusted 
 * gross income and expenses in customer data.
 *
 * see tax code 26 U.S. Code A.1.B, PART VI
 */
float computeDeductions(float agi, Expenses expenses);
```

![Tax computation system with three components](tax-decomposition.png)
<!-- .element: class="stretch" -->
</script></section><section data-markdown><script type="text/template">## Strict Correctness Assumption

* Specification determines which outputs are correct/wrong
* Not "pretty good", "95% accurate", or "correct for 98% of all users"
* A single wrong result indicates a bug in the system

![Tax computation system with three components](tax-decomposition.png)
<!-- .element: class="stretch" -->

<aside class="notes"><p>A single wrong tax prediction would be a bug. No tolerance of occasional wrong predictions, approximations, nondeterminism.</p>
</aside></script></section><section data-markdown><script type="text/template">## Image Captioning Algorithm


![Image captioning one step](imgcaptioning.png)

```java
/**
  ????
*/
String getCaption(Image img);
```

<aside class="notes"><p>We do not know how to program this or specify this.
No way of saying whether caption is &quot;correct&quot; for input, but defer to human judgement.</p>
</aside></script></section><section data-markdown><script type="text/template">## Learning Image Captioning Algorithm

![Image captioning with ML](imgcaptioningml.png)


*Learning rules by fitting to examples, no specification, inductive reasoning*

<aside class="notes"><p>&quot;Rules&quot;/algorithm learned from data. Still no specification. Best fit to given training data.</p>
</aside></script></section><section data-markdown><script type="text/template">## Correctness of Model?

<!-- colstart -->
![Example of wrong caption](imgcaptioning-cake.png)
<!-- col -->
> All models are wrong, but some are useful. -- George Box
<!-- colend -->

<!-- references -->
Image from: Nushi, Besmira, Ece Kamar, Eric Horvitz, and Donald Kossmann. "[On human intellect and machine failures: troubleshooting integrative machine learning systems](http://erichorvitz.com/human_repair_AI_pipeline.pdf)." In Proc. AAAI. 2017.

<aside class="notes"><p>Human judgment needed. Furthermore, a single bad example is not a problem.</p>
</aside></script></section><section data-markdown><script type="text/template">## Weak Correctness Assumptions

* Often no reliable ground truth (e.g. human judgment)
* Accepting that mistakes will happen, hopefully not to frequently; "95% accuracy" may be pretty good
* More confident for data similar to training data

![Example of wrong caption](imgcaptioning-cake.png)
<!-- .element: class="stretch" -->

</script></section><section data-markdown><script type="text/template">## Specifications in Machine Learning?

* Usually clear specifications do not exist -- we use machine learning exactly because we do not know the specifications
* Can define correctness for some data, but not general rules; sometimes can only determine correctness after the fact
* Learning for tasks for which we cannot write specifications
  * Too complex
  * Rules unknown
* ML will learn rules/specifications (inductive reasoning), often not in a human-readable form, but are those the right ones?
* 
* Usually goals used instead --> maximize a specific objective

</script></section><section data-markdown><script type="text/template">
[![Contrasting inductive and deductive reasoning](inductive.png)](https://danielmiessler.com/blog/the-difference-between-deductive-and-inductive-reasoning/)
<!-- .element: class="stretch" -->


(Daniel Miessler, CC SA 2.0)
</script></section><section data-markdown><script type="text/template">
## Deductive Reasoning

* Combining logical statements following agreed upon rules to form new statements
* Proving theorems from axioms
* From general to the particular
* *mathy reasoning, eg. proof that π is irrational*
* 
* Formal methods, classic rule-based AI systems, expert systems

<!-- split -->

## Inductive Reasoning

* Constructing axioms from observations
* Strong evidence suggests a rule
* From particular to the general
* *sciency reasoning, eg. finding laws of nature*
* 
* Most modern machine learning systems, statistical learning

</script></section><section data-markdown><script type="text/template">## Consequences from Lack of Specifications

<!-- discussion -->


<aside class="notes"><p>Breaks many traditional assumptions and foundations for compositional reasoning and divide and conquer</p>
<p>Poorly understood interactions between models:
Ideally, develop models separately &amp; compose together.
In general, must train &amp; tune together.</p>
</aside></script></section><section data-markdown><script type="text/template">## Decomposing the Image Captioning Problem?

![Image of a snowboarder](snowboarder.png)

<aside class="notes"><p>Using insights of how humans reason: Captions contain important objects in the image and their relations. Captions follow typical language/grammatical structure</p>
</aside></script></section><section data-markdown><script type="text/template">## State of the Art Decomposition (in 2015)

![Captioning example](imgcaptioningml-decomposed.png)

<!-- references -->
Example and image from: Nushi, Besmira, Ece Kamar, Eric Horvitz, and Donald Kossmann. "[On human intellect and machine failures: troubleshooting integrative machine learning systems](http://erichorvitz.com/human_repair_AI_pipeline.pdf)." In Proc. AAAI. 2017.

</script></section><section data-markdown><script type="text/template">## Blame assignment?

![blame assignment problem](imgcaptioningml-blame.png)

<!-- references -->
Example and image from: Nushi, Besmira, Ece Kamar, Eric Horvitz, and Donald Kossmann. "[On human intellect and machine failures: troubleshooting integrative machine learning systems](http://erichorvitz.com/human_repair_AI_pipeline.pdf)." In Proc. AAAI. 2017.
</script></section><section data-markdown><script type="text/template">## Nonmonotonic errors

![example of nonmonotonic error](imgcaptioningml-nonmonotonic.png)

<!-- references -->
Example and image from: Nushi, Besmira, Ece Kamar, Eric Horvitz, and Donald Kossmann. "[On human intellect and machine failures: troubleshooting integrative machine learning systems](http://erichorvitz.com/human_repair_AI_pipeline.pdf)." In Proc. AAAI. 2017.

</script></section><section data-markdown><script type="text/template">## Takeaway: Shift in Design Thinking?

Breaking traditional decomposition and reasoning strategies... 

From deductive reasoning to inductive reasoning...

From clear specifications to goals...

From guarantees to best effort...

**What does this mean for software engineering?**

**For decomposing software systems?** 

**For correctness of AI-enabled systems?** 

**For safety?**

**For design, implementation, testing, deployment, operations?**


*These problems are not new, but are exacerbated by the increasing use of ML!*
























</script></section></section><section  data-markdown><script type="text/template"># Summary

* ML changes many engineering assumptions; from deductive to inductive reasoning; consequences for composition and abstraction
* Production AI-enabled systems require a *whole system perspective*, beyond just the model
* Engineering pipelines not models
* Large design space for user interface (intelligent experience): forcefulness, frequency, telemetry
* Quality at a *system* level: safety beyond the model, beyond accuracy

</script></section><section  data-markdown><script type="text/template"># Recommended Readings

* 🗎 Wagstaff, Kiri. "[Machine learning that matters](https://arxiv.org/abs/1206.4656)." In Proceedings of the 29th International Conference on Machine Learning, (2012).
* 🗎 Sculley, David, Gary Holt, Daniel Golovin, Eugene Davydov, Todd Phillips, Dietmar Ebner, Vinay Chaudhary, Michael Young, Jean-Francois Crespo, and Dan Dennison. "[Hidden technical debt in machine learning systems](http://papers.nips.cc/paper/5656-hidden-technical-debt-in-machine-learning-systems.pdf)." In Advances in neural information processing systems, pp. 2503-2511. 2015.
* 🗎 Nushi, Besmira, Ece Kamar, Eric Horvitz, and Donald Kossmann. "[On human intellect and machine failures: troubleshooting integrative machine learning systems](http://erichorvitz.com/human_repair_AI_pipeline.pdf)." In *Proceedings of the Thirty-First AAAI Conference on Artificial Intelligence*, pp. 1017-1025. 2017.
* 🗎 O'Leary, Katie, and Makoto Uchida. "[Common problems with Creating Machine Learning Pipelines from Existing Code](https://research.google/pubs/pub48984.pdf)." Proc. Third Conference on Machine Learning and Systems (MLSys) (2020).
* Blog post: [On the process for building software with ML components](https://ckaestne.medium.com/on-the-process-for-building-software-with-ml-components-c54bdb86db24)</script></section></div>
    </div>

    <script src="./../js/reveal.js"></script>

    <script>
      function extend() {
        var target = {};
        for (var i = 0; i < arguments.length; i++) {
          var source = arguments[i];
          for (var key in source) {
            if (source.hasOwnProperty(key)) {
              target[key] = source[key];
            }
          }
        }
        return target;
      }

      // Optional libraries used to extend on reveal.js
      var deps = [
        { src: './../plugin/markdown/marked.js', condition: function() { return !!document.querySelector('[data-markdown]'); } },
        { src: './../plugin/markdown/markdown.js', condition: function() { return !!document.querySelector('[data-markdown]'); } },
        { src: './../plugin/highlight/highlight.js', async: true, callback: function() { hljs.initHighlightingOnLoad(); } },
        { src: './../plugin/zoom-js/zoom.js', async: true },
        { src: './../plugin/notes/notes.js', async: true },
        { src: './../plugin/math/math.js' },
        { src: './../rplugin/embed-tweet/embed-tweet.js' },
        { src: './../rplugin/menu/menu.js', async: true },
        { src: './../rplugin/spreadsheet/spreadsheet.js' },
        { src: './../rplugin/chalkboard/chalkboard.js', async: true }
      ];

      // default options to init reveal.js
      var defaultOptions = {
        controls: true,
        progress: true,
        history: true,
        center: true,
        transition: 'default', // none/fade/slide/convex/concave/zoom
        dependencies: deps,
	chalkboard: { // font-awesome.min.css must be available
		toggleChalkboardButton: { left: "80px" },
		toggleNotesButton: { left: "130px" },
	},
	keyboard: {
	    67: function() { RevealChalkboard.toggleNotesCanvas() },	// toggle notes canvas when 'c' is pressed
	    66: function() { RevealChalkboard.toggleChalkboard() },	// toggle chalkboard when 'b' is pressed
	    46: function() { RevealChalkboard.clear() },	// clear chalkboard when 'DEL' is pressed
	     8: function() { RevealChalkboard.reset() },	// reset chalkboard data on current slide when 'BACKSPACE' is pressed
	    68: function() { RevealChalkboard.download() },	// downlad recorded chalkboard drawing when 'd' is pressed
	    88: function() { RevealChalkboard.colorNext() },	// cycle colors forward when 'x' is pressed
	    89: function() { RevealChalkboard.colorPrev() },	// cycle colors backward when 'y' is pressed
	}
      };

      // options from URL query string
      var queryOptions = Reveal.getQueryHash() || {};

      var options = extend(defaultOptions, {"controls":true,"progress":true,"theme":"white","slideNumber":true,"hash":true,"center":false}, queryOptions);
    </script>

    <script src="./../_assets/_assets/viz.js"></script>
    <script src="./../_assets/_assets/loadmymarkdown.js"></script>

    <script>
      Reveal.initialize(options);
    </script>
  </body>
</html>

<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no" />

    <title>17-445: Usability</title>
    <link rel="stylesheet" href="./../css/reveal.css" />
    <link rel="stylesheet" href="./../css/theme/white.css" id="theme" />
    <link rel="stylesheet" href="./../css/highlight/zenburn.css" />
    <link rel="stylesheet" href="./../css/print/paper.css" type="text/css" media="print" />
    <link rel="stylesheet" href="./../_assets/_assets/cmu.css" />

  </head>
  <body>
    <div class="reveal">
      <div class="slides"><div id="footer">17-445 Software Engineering for AI-Enabled Systems, Christian Kaestner & Eunsuk Kang</div><section  data-markdown><script type="text/template">

# Usability

Eunsuk Kang

<!-- references -->

Required reading: Building Intelligent Systems by Geoff Hulten (2018),
Chapter 8.
</script></section><section  data-markdown><script type="text/template"># Learning Goals

* Understand key ingredients of usable experiences (UX)
* Discuss factors to consider when designing UX for AI-enabled systems
</script></section><section ><section data-markdown><script type="text/template"># Usability
</script></section><section data-markdown><script type="text/template">## Case Study: Voice-Controlled Intelligent Assistants

![](echo.jpg)
</script></section><section data-markdown><script type="text/template">## Dimensions of Usability

* __Learnability__: How easy is it for users to accomplish tasks the first time?
* __Efficiency__: After learning, how efficiently can users perform the
  tasks?
* __Memorability__: Can users remember to perform the tasks after a period of
  not using the system?
* __Errors__: How often do users make errors, how severe are these errors, and how easily can they recover from the errors?
* __Satisfaction__: How pleasant is it to use the design?

<!-- references -->

https://www.nngroup.com/articles/usability-101-introduction-to-usability/
</script></section><section data-markdown><script type="text/template">## Interaction Cost

![](word-funny.png)

* Mental + physical effort to perform a desired task
  * Reading, scrolling, clicking, typing, attention switch, memory load...
* __Goal of usable design__: Minimize interaction cost while allowing users to achieve
  their goals
* Q. What impact does AI have on interaction cost?

</script></section><section data-markdown><script type="text/template">##  Interaction Cost for Intelligent Assistants

![](echo.jpg)

* Holy grail of UX design: Reduce interaction cost to zero
* Q. Is the cost actually smaller than in physical interfaces?
</script></section></section><section ><section data-markdown><script type="text/template"># Designing Usable Interfaces for AI
</script></section><section data-markdown><script type="text/template">## Considerations for Usable AI Design

* User needs: Automate or augment?
* Mental model
* Error handling
* Feedback & control
</script></section><section data-markdown><script type="text/template">## User Needs for AI

* Identify the tasks that the user wants to achieve
* For each task, decide between __automate vs. augment__
  * Is AI good for this particular task?
* Automate when:
  <!-- .element: class="fragment" -->
  * User lacks knowledge/ability to perform the task (e.g., prediction)
    <!-- .element: class="fragment" -->
  * Boring, repetitive, dangerous tasks
    <!-- .element: class="fragment" -->
* Augment when:
<!-- .element: class="fragment" -->
  * High stakes & accountability needed
     <!-- .element: class="fragment" -->
  * Difficult to communicate user's need to AI
     <!-- .element: class="fragment" -->
  * User enjoys performing the task (e.g., driving)
     <!-- .element: class="fragment" -->
</script></section><section data-markdown><script type="text/template">##  User Needs for Intelligent Assistant

![](echo.jpg)

* What user needs are intelligent assistants designed to fulfill?
* Which of these are automated? Augmented?
</script></section><section data-markdown><script type="text/template">## Mental Model

![](mental-model.jpg)

* What the user believes about the system
<!-- .element: class="fragment" -->
  * Plans actions based on the model
  * Belief, not facts: May not reflect the reality, only what
    user believes
* Challenge: Align system with the user's mental model
<!-- .element: class="fragment" -->
  * Mismatch between user's & designer's mental models
  * User's model preconceived based on prior experience
  * User's model evolving over time
</script></section><section data-markdown><script type="text/template">## Example: Shopping Cart Checkout 

![](checkout-flow.jpg)

1. Browse for items
2. Add items to cart
3. Choose checkout
4. Enter shipping & billing data
5. Press submit
6. Get confirmation

Mental model = A __linear__ sequence of familiar steps
</script></section><section data-markdown><script type="text/template">## Breaking Mental Model

![](sony-checkout.png)

* Anti-pattern: Interrupt linear flow & bring user back to a 
  previous step
  * Create an account, open a new dialog to enter
    preferred address...
  * Breaks user's mental model => failure to convert into sales
* ~60% of customers abandon their shopping cart

<!-- references -->
https://baymard.com/blog/checkout-process-should-be-linear
</script></section><section data-markdown><script type="text/template">## Mental Model for AI-Based Systems

![](ml-mental-model.jpg)

* User: "What is the AI doing, and how do I use it?"
  * Typically less transparent than traditional applications
* Unclear inputs: What are possible actions? Which of these actions matter? When
does my action take effect?
<!-- .element: class="fragment" -->
* Lack of control over output: Why am I being given these
  recommendations? Why is the output displayed in this order?
<!-- .element: class="fragment" -->

<!-- references -->
https://www.nngroup.com/articles/machine-learning-ux/
</script></section><section data-markdown><script type="text/template">## Design Principles: Mental Model 

* Identify user's existing mental models
<!-- .element: class="fragment" -->
  * Find similar apps & identify common patterns
* Make the system conform to the user's mental model
  <!-- .element: class="fragment" -->
  * Collect & analyze errors made by user
  * Do these point to a mismatch vs. user's mental model?
* Improve/adjust the user's mental model
<!-- .element: class="fragment" -->
  * Set user's expectations through onboarding 
  * Increase transparency and explain decisions made by AI
</script></section><section data-markdown><script type="text/template">## Onboarding: Setting User's Expectations

![](grammar.png)

* Be clear about what AI can(not) do
* Provide examples of how it works
</script></section><section data-markdown><script type="text/template">## Explaining Decisions

![](why-am-i-seeing-this-post-v1.png)

* Explain how user's actions influence output
</script></section><section data-markdown><script type="text/template">##  Mental Model for Intelligent Assistants?

![](echo.jpg)

* What can it do? What are its limitations?
* How do I get it to do/say  X?
* Why did it do/say Y instead of X? 
</script></section><section data-markdown><script type="text/template">## Mental Model for Intelligent Assistants

![](ia-completion.jpg)

* Reasons for failures:
  * (1) User doesn't know how to get AI to do X
  * (2) User says X, but AI simply can't do X
* Users settle on simpler tasks over time; small but limited improvements
</script></section><section data-markdown><script type="text/template">## Failing to User's Expectations 

>“So, this week, I realized that I don't use my IA nearly as much as I thought I did. I do use it often. However it's very much normally the same like five things over and over again."

* Poor UX design => User settles on a suboptimal mental model & fails to benefit from the full capabilities of AI.
* Q. What are some possible ways to improve user's mental model?
  Onboarding? Explaining outcomes?

<!-- references -->

https://www.nngroup.com/articles/mental-model-ai-assistants/
</script></section><section data-markdown><script type="text/template">## Dealing with Errors

* Define errors & failures
<!-- .element: class="fragment" -->
  * User errors: Mistakes made by users (e.g., click on a wrong button)
  * System errors: Failure of a system to provide correct outcome
    (e.g., bad movie recommendation)
* Detect & record occurrences of errors
<!-- .element: class="fragment" -->
* Identify sources of errors
<!-- .element: class="fragment" -->
  * User errors: Mismatched mental model or poor UX design
  * System errors: Poor model accuracy, training data, etc.,
* Provide actionable error messages & guidelines
<!-- .element: class="fragment" -->
</script></section><section data-markdown><script type="text/template">## Error Messages: Suggest user actions

![](run-ai-example.png)

* Guide the user towards ways to recover from/prevent further errors

<!--references -->

https://pair.withgoogle.com/chapter/errors-failing/
</script></section><section data-markdown><script type="text/template">## Errors in Intelligent Assistants

![](echo.jpg)

* What errors are made by users? What are the sources of errors?
* Errors made by AI? Sources?
</script></section><section data-markdown><script type="text/template">## Errors in Intelligent Assistants

> “...sometimes it says it does — like the reminders and the sending messages. It says it will do it. But then at the end we found that it didn’t really send the message.”

* How do we detect an error?
* How can we notify/guide the user when an error occurs?

<!-- references -->

https://www.nngroup.com/articles/mental-model-ai-assistants/
</script></section><section data-markdown><script type="text/template">## Feedback and Control

* Implicit feedback: Data about user behaviors collected by system
<!-- .element: class="fragment" -->
  * e.g., times of day, duration of usage, 
    recommendations accepted/rejected, click patterns, etc.,
* Explicit feedback: Prompted or deliberately provided by user
<!-- .element: class="fragment" -->
  * Surveys, ratings, thumbs up, feedback forms, etc., 
* Design considerations for feedback
<!-- .element: class="fragment" -->
  * Align feedback with improving interactions (and AI)
  * Acknowledge user feedback & respond immediately 
* In addition to feedback, provide a way for user to adjust AI behavior
<!-- .element: class="fragment" -->
</script></section><section data-markdown><script type="text/template">## Responding to Feedback 

![](run-feedback-example.jpg)

* When possible, respond to feedback with an adjustment to AI behavior

<!-- references -->

https://pair.withgoogle.com/chapter/feedback-controls/
</script></section><section data-markdown><script type="text/template">## Giving User Control 

![](run-control-example.jpg)

* Provide mechanisms for user to adjust AI behavior
</script></section><section data-markdown><script type="text/template">## Feedback & Control in Intelligent Assistants

![](echo.jpg)

* How do we collect user feedback? Implicit? Explicit?
* What kind of control do we provide to the user?
</script></section><section data-markdown><script type="text/template">##  User Feedback in Intelligent Assistants

> "All of the things that even Siri herself said she could do — for example ‘I can send money via Venmo, just try and say this.’ I tried and it didn’t work, and maybe there are settings that I need to fix. But when those types of things happened, there was no button that said ‘Hey, in order to make this work in the future, click this and we’ll take you to the permissions or whatever’."

<!-- references -->
https://www.nngroup.com/articles/mental-model-ai-assistants/
</script></section></section><section  data-markdown><script type="text/template"># Summary

* Goal of usable design: Minimize interaction cost 
  * Automation does not necessarily imply reduced cost!
* UX design considerations for AI
  * User needs: Automate or augment?
  * Mental model: Explain to user what AI is doing
  * Dealing with errors: Guide user towards recovery & prevention
  * Feedback and control: Align user feedback with AI improvement
</script></section></div>
    </div>

    <script src="./../js/reveal.js"></script>

    <script>
      function extend() {
        var target = {};
        for (var i = 0; i < arguments.length; i++) {
          var source = arguments[i];
          for (var key in source) {
            if (source.hasOwnProperty(key)) {
              target[key] = source[key];
            }
          }
        }
        return target;
      }

      // Optional libraries used to extend on reveal.js
      var deps = [
        { src: './../lib/js/classList.js', condition: function() { return !document.body.classList; } },
        { src: './../plugin/markdown/marked.js', condition: function() { return !!document.querySelector('[data-markdown]'); } },
        { src: './../plugin/markdown/markdown.js', condition: function() { return !!document.querySelector('[data-markdown]'); } },
        { src: './../plugin/highlight/highlight.js', async: true, callback: function() { hljs.initHighlightingOnLoad(); } },
        { src: './../plugin/zoom-js/zoom.js', async: true },
        { src: './../plugin/notes/notes.js', async: true },
        { src: './../plugin/math/math.js', async: true }
      ];

      // default options to init reveal.js
      var defaultOptions = {
        controls: true,
        progress: true,
        history: true,
        center: true,
        transition: 'default', // none/fade/slide/convex/concave/zoom
        dependencies: deps
      };

      // options from URL query string
      var queryOptions = Reveal.getQueryHash() || {};

      var options = extend(defaultOptions, {"controls":true,"progress":true,"theme":"white","slideNumber":true,"hash":true,"center":false}, queryOptions);
    </script>

    <script src="./../_assets/_assets/mermaid.min.js"></script>
    <script src="./../_assets/_assets/loadmymarkdown.js"></script>

    <script>
      Reveal.initialize(options);
    </script>
  </body>
</html>

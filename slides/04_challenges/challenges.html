<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no" />

    <title>17-445: Challenges and Measurements</title>
    <link rel="stylesheet" href="./../css/reveal.css" />
    <link rel="stylesheet" href="./../css/theme/white.css" id="theme" />
    <link rel="stylesheet" href="./../css/highlight/zenburn.css" />
    <link rel="stylesheet" href="./../css/print/paper.css" type="text/css" media="print" />
    <link rel="stylesheet" href="./../_assets/_assets/cmu.css" />

  </head>
  <body>
    <div class="reveal">
      <div class="slides"><div id="footer">17-445 Software Engineering for AI-Enabled Systems, Christian Kaestner & Eunsuk Kang</div><section  data-markdown><script type="text/template">  

# Challenges and Measurements

Eunsuk Kang

<!-- references -->

Readings: D. Sculley et al. "Hidden Technical Debt in Machine Learning
Systems" (2015) 

Hulten, Geoff. "Building Intelligent Systems: A Guide to Machine
Learning Engineering" (2018), Chapter 4.
</script></section><section  data-markdown><script type="text/template"># Learning Goals

* Understand:
  * Challenges in building AI-based systems
  * Key differences from traditional software
  * Use of measurements in AI-based systems 
  * Difficulty and validity of measurements
  * Limitations and risks of decisions and incentives based
on measurements
</script></section><section ><section data-markdown><script type="text/template"># Challenges in Developing AI-Enabled Systems
</script></section><section data-markdown><script type="text/template">## Traditional Programming vs ML

![Programming vs ML](programming-vs-ml.png)
</script></section><section data-markdown><script type="text/template">## Complexity in Engineering Systems

![Airplane](airplane.jpg)

* Automobile: ~30,000 parts; Airplane: ~3,000,000 parts
* MS Office: ~ 40,000,000 LOCs; Debian: ~ 400,000,000 LOCs

### Q. How do we build such complex systems?
</script></section><section data-markdown><script type="text/template">## Managing Complexity in Software

* **Abstraction**: Hide details & focus on high-level behaviors
* **Reuse**: Package into reusable libraries & APIs with well-defined _contracts_
* **Composition**: Build large components out of smaller ones

```java
class Algorithms {
    /**
     * Finds the shortest distance between to vertices.
	 * This method is only supported for connected vertices.
     */
    int shortestDistance(Graph g, Vertice v1, v2) {…}
}
```
</script></section><section data-markdown><script type="text/template">## Contracts in ML?

![Vision contract](vision.png)

**Q. Is this the same kind of contract as in software?**
</script></section><section data-markdown><script type="text/template">## (Lack of) Modularity in ML

* Often no clear specification of "correct" behavior
  <!-- .element: class="fragment" -->
  * Optimizing metrics instead of providing guarantees
* Model behavior strongly dependent on training & test sets
  <!-- .element: class="fragment" -->
  * What happens if distribution changes?
* Poorly understood interactions between models
  <!-- .element: class="fragment" -->
  * Ideally, develop models separately & compose together
  * In general, must train & tune together
</script></section><section data-markdown><script type="text/template">## Concept Drifts

* ML estimates "f(x) = y"
<!-- .element: class="fragment" -->
  * What if the relationship between "x" & "y" changes over time? 
  * What if "f" does not capture certain relationships?
* Q. Examples?
<!-- .element: class="fragment" -->
* In general, impossible to predict
<!-- .element: class="fragment" -->
	* Continuously monitor and update model
</script></section><section data-markdown><script type="text/template">## Feedback loops

* Every system is deployed as part of an environment
<!-- .element: class="fragment" -->
* Output influences the environment
<!-- .element: class="fragment" -->
  * In turn, affects input back to the system
  * Over time, may lead to undesirable (and difficult to reverse) outcome
  * Higher risks if initial data set & model is biased

![Feedback Loop](feedback-loop.png)
</script></section><section data-markdown><script type="text/template">## Example: Crime Prediction

* Use past data to predict crime rates 
* Police increases the frequency of patrol in area X
* More arrested made in area X
* New crime data fed back to the model
* Repeat

![Crime Map](crime-map.jpg)
</script></section><section data-markdown><script type="text/template">## Discussion: Product Recommendations

![Product recommendations](recommendations.png)

* Specification/metrics?
* Concept drift?
* Feedback loop?
</script></section></section><section ><section data-markdown><script type="text/template"># Introduction to Measurements
</script></section><section data-markdown><script type="text/template">## What is Measurement?

* _Measurement is the empirical, objective assignment of numbers,
according to a rule derived from a model or theory, to attributes of
objects or events with the intent of describing them._ – Craner, Bond,
“Software Engineering Metrics: What Do They Measure and How Do We
Know?"

* 	_A quantitatively expressed reduction of uncertainty based on one or more observations._ – Hubbard, “How to Measure Anything …"
</script></section><section data-markdown><script type="text/template">## Measurement for Decision Making

* Which project to fund?
* Need more system testing?
* Need more training?
* Fast enough? Secure enough? 
* Code quality sufficient?
* Which features to focus on?
* Developer bonus?
* Time and cost estimation? Predictions reliable?
</script></section><section data-markdown><script type="text/template">## Measurement Scales

* Scale: The type of data being measured.
<!-- .element: class="fragment" -->
  * Dictates what sorts of analysis/arithmetic is legitimate or meaningful.
* Nominal: Categories
<!-- .element: class="fragment" -->
  * e.g., biological species, film genre, nationality
* Ordinal: Order, but no meaningful magnitude
<!-- .element: class="fragment" -->
  * Difference between two values is not meaningful
  * Even if numbers are used, they do not represent magnitude!
  * e.g., weather severity, complexity classes in algorithms
* Interval: Order, magnitude, but no definition of zero.
<!-- .element: class="fragment" -->
  * 0 is an arbitrary point; does not represent absence of quantity
  * Ratio between values are not meaningful
  * e.g., temperature (C or F)
* Ratio: Order, magnitude, and zero.
<!-- .element: class="fragment" -->
  * e.g., mass, length, temperature (Kelvin)
</script></section><section data-markdown><script type="text/template">##  Measurement Scales 

![scales](scales.png)
</script></section><section data-markdown><script type="text/template">## Measurements in AI-Enabled Systems

* Organizational objectives
<!-- .element: class="fragment" -->
  * e.g., revenues, growth, lives saved, societal benefits 
  * Often not directly measurable from system output; slow indicators
* Leading indicators
<!-- .element: class="fragment" -->
  * Customer sentiment: Do they like the product?
  * Customer engagement: How often do they use the product?
  * But can be misleading (more daily active users => higher profits?)
* User outcomes
<!-- .element: class="fragment" -->
	* Does the system achieve what it promises to users?
* Model Properties
<!-- .element: class="fragment" -->
  * Accuracy of predictions, error rates
  * Performance (e.g., prediction time)
  * Cost: Training time, amount of data required
</script></section><section data-markdown><script type="text/template">## Exercise: Metrics in Product Recommender

![Product recommendations](recommendations.png)

* Organization objectives?
* Leading indicators?
* User outcomes?
* Model properties?
* What are their scales?
</script></section></section><section ><section data-markdown><script type="text/template"># Challenges in Measurements
</script></section><section data-markdown><script type="text/template">## The streetlight effect

* A type of _observational bias_
* People tend to look for something where it’s easiest to do so.

![Streetlight](streetlight.jpg)
</script></section><section data-markdown><script type="text/template">## Risks with Measurements

* Bad statistics: A basic misunderstanding of measurement theory and what is being measured.
<!-- .element: class="fragment" -->
* Bad decisions: The incorrect use of measurement data, leading to unintended side effects.
<!-- .element: class="fragment" -->
* Bad incentives: Disregard for the human factors, or how the cultural change of taking measurements will affect people.
<!-- .element: class="fragment" -->
</script></section><section data-markdown><script type="text/template">## Risks of Metrics as Incentives

* Metrics-driven incentives can:
<!-- .element: class="fragment" -->
  * Extinguish intrinsic motivation
  * Diminish performance
  * Encourage cheating, shortcuts, and unethical behavior
  * Become addictive
  * Foster short-term thinking
* Often, different stakholders have different incentives!
<!-- .element: class="fragment" -->
</script></section><section data-markdown><script type="text/template">## Another Case Study: University Rankings

![US News](us-news.jpg)

* Originally: Opinion-based polls, but schools complained
* Data-driven model: Rank colleges in terms of "educational excellence"
* Input: SAT scores, student-teacher ratios, acceptance rates,
retention rates, alumni donations, etc.,
</script></section><section data-markdown><script type="text/template">## Discussion: University Rankings

![US News](us-news.jpg)

* What is (not) being measured? Any streetlight effect?
* Is the measured data being used correctly?
* Are incentives for using these data good? Can they be misused?
</script></section><section data-markdown><script type="text/template">## Examples: Risks of Metrics as Incentives

* Example 1
  <!-- .element: class="fragment" -->
  * Schools optimize metrics for higher ranking (add new classrooms, nicer
  facilities)
  * Tuition increases, but is not part of the model!
  * Higher ranked schools become more expensive
  * Advantage to students from wealthy families
* Example 2
  <!-- .element: class="fragment" -->
  * A university founded in early 2010's
  * Math department ranked by US News as top 10 worldwide
  * Top international faculty paid $$ as a visitor; asked to add affiliation
  * Increase in publication citations => skyrocket ranking!
  </script></section><section data-markdown><script type="text/template">## Measurement Validity

* Construct: Are we measuring what we intended to measure?
<!-- .element: class="fragment" -->
  * Does the abstract concept match the specific scale/measurement used?
  * e.g., IQ: What is it actually measuring?
  * Other examples: Pain, language proficiency, personality...
* Predictive: The extent to which the measurement can be used to explain some other characteristic of the entity being measured
<!-- .element: class="fragment" -->
	* e.g., Higher SAT scores => higher academic excellence?
* External validity: Concerns the generalization of the findings to contexts and environments, other than the one studied
<!-- .element: class="fragment" -->
	* e.g., Drug effectiveness on test group: Does it hold over the general public? 
</script></section><section data-markdown><script type="text/template">##  Correlation vs Causation

![causation1](causation1.png)

![causation2](causation2.png)
</script></section><section data-markdown><script type="text/template">##  Correlation vs Causation

* In general, ML learns correlation, not causation
<!-- .element: class="fragment" -->
	* (exception: Bayesian networks, certain symbolic AI methods)
* To establish causality:
<!-- .element: class="fragment" -->
  * Develop a theory ("X causes Y") based on domain knowledge & independent data
  * Identify relevant variables
  * Design a controlled experiment & show correlation
  * Demonstrate ability to predict new cases
  </script></section><section data-markdown><script type="text/template">## Confounding Variables

![confounding](confounding.png)

* If you want to show correlation between X and Y:
  * Identify potential confounding variables 
  * Control for those variables during measurement
* Examples
  * Drink coffee => Pancreatic cancer?
  * Degree from high-ranked schools => Higher-paying jobs?
  </script></section><section data-markdown><script type="text/template">## Successful Measurement Program

* Set solid measurement objectives and plans.
* Make measurement part of the process.
* Gain a thorough understanding of measurement.
* Focus on cultural issues.
* Create a safe environment to collect and report true data.
* Cultivate a predisposition to change.
* Develop a complementary suite of measures.
</script></section><section data-markdown><script type="text/template">## Recitation This Week

![jmeter](apache-jmeter.png)

### Apache JMeter: Performance Measuring Tool
</script></section></section><section  data-markdown><script type="text/template"># Summary

* Challenges in ML: Lack of specification, concept drift, feedback loop 
* Introduction to measurements: Scales, validity, correlation & causation
* Risks with measurements: Incentives & misuse
  * Think about feedback loops & potential societal impact!

</script></section></div>
    </div>

    <script src="./../js/reveal.js"></script>

    <script>
      function extend() {
        var target = {};
        for (var i = 0; i < arguments.length; i++) {
          var source = arguments[i];
          for (var key in source) {
            if (source.hasOwnProperty(key)) {
              target[key] = source[key];
            }
          }
        }
        return target;
      }

      // Optional libraries used to extend on reveal.js
      var deps = [
        { src: './../lib/js/classList.js', condition: function() { return !document.body.classList; } },
        { src: './../plugin/markdown/marked.js', condition: function() { return !!document.querySelector('[data-markdown]'); } },
        { src: './../plugin/markdown/markdown.js', condition: function() { return !!document.querySelector('[data-markdown]'); } },
        { src: './../plugin/highlight/highlight.js', async: true, callback: function() { hljs.initHighlightingOnLoad(); } },
        { src: './../plugin/zoom-js/zoom.js', async: true },
        { src: './../plugin/notes/notes.js', async: true },
        { src: './../plugin/math/math.js', async: true }
      ];

      // default options to init reveal.js
      var defaultOptions = {
        controls: true,
        progress: true,
        history: true,
        center: true,
        transition: 'default', // none/fade/slide/convex/concave/zoom
        dependencies: deps
      };

      // options from URL query string
      var queryOptions = Reveal.getQueryHash() || {};

      var options = extend(defaultOptions, {"controls":true,"progress":true,"theme":"white","slideNumber":true,"hash":true,"center":false}, queryOptions);
    </script>

    <script src="./../_assets/_assets/mermaid.min.js"></script>
    <script src="./../_assets/_assets/loadmymarkdown.js"></script>

    <script>
      Reveal.initialize(options);
    </script>
  </body>
</html>

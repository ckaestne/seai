<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no" />

    <title>17-645: Planning for Mistakes</title>
    <link rel="shortcut icon" href="./../favicon.ico" />
    <link rel="stylesheet" href="./../dist/reset.css" />
    <link rel="stylesheet" href="./../dist/reveal.css" />
    <link rel="stylesheet" href="./../dist/theme/white.css" id="theme" />
    <link rel="stylesheet" href="./../css/highlight/base16/zenburn.css" />
    <link rel="stylesheet" href="./../_assets/cmu.css" />

    <link rel="stylesheet" type="text/css" href="//fonts.googleapis.com/css?family=Lato" />

    <!-- <link rel="stylesheet" href="./../css/print/paper.css" type="text/css" media="print" /> -->

  </head>
  <body>
    <div class="reveal">
      <div class="slides"><div id="footer">17-645 Machine Learning in Production ‚Ä¢ Christian Kaestner, Carnegie Mellon University ‚Ä¢ Fall 2022</div><section  data-markdown><script type="text/template">  
<!-- .element: class="titleslide"  data-background="../_chapterimg/07_mistakes.jpg" -->
<div class="stretch"></div>

## Machine Learning in Production

# Planning for Mistakes

</script></section><section ><section data-markdown><script type="text/template">## Exploring Requirements...

![Overview of course content](../_assets/overview.svg)
<!-- .element: class="plain stretch" -->

</script></section><section data-markdown><script type="text/template">## Learning goals:

* Consider ML models as unreliable components
* Use safety engineering techniques FTA, FMEA, and HAZOP to anticipate and analyze possible mistakes 
* Design strategies for mitigating the risks of failures due to ML mistakes
</script></section><section data-markdown><script type="text/template">## Readings



Required reading: Hulten, Geoff. "Building Intelligent Systems: A
Guide to Machine Learning Engineering." (2018), Chapters 6‚Äì7 (Why
creating IE is hard, balancing IE) and 24 (Dealing with mistakes)


</script></section></section><section ><section data-markdown><script type="text/template"># ML Models = Unreliable Components
</script></section><section data-markdown><script type="text/template">## Models make mistakes

![Goats in a tree](goats.jpg)
<!-- .element: class="stretch" -->

</script></section><section data-markdown><script type="text/template">## Models make mistakes

<div class="tweet" data-src="https://twitter.com/WorldBollard/status/1567226144197607424"></div>

</script></section><section data-markdown><script type="text/template">## Common excuse: Nobody could have foreseen this...

![Suicide rate of girls rising with the rise of social media](teen-suicide-rate.png)
</script></section><section data-markdown><script type="text/template">## Common excuse: Software mistake -- nobody's fault

<div class="tweet" data-src="https://twitter.com/dhh/status/1192945019230945280"></div>

</script></section><section data-markdown><script type="text/template">## Common excuse: just software mistake

<div class="tweet" data-src="https://twitter.com/nke_ise/status/897756900753891328"></div>

</script></section><section data-markdown><script type="text/template">## What responsibility do designers have to anticipate problems?

![Critical headline about predictive policing](predictive-policing.png)


</script></section><section data-markdown><script type="text/template">## Sources of Wrong Predictions?

<!-- discussion -->

</script></section><section data-markdown><script type="text/template">## Correlation vs Causation

![causation1](causation1.png)

![causation2](causation2.png)
</script></section><section data-markdown><script type="text/template">## Confounding Variables

![Confounding variable example](confoundingvariables.svg)
<!-- .element: class="plain" -->
</script></section><section data-markdown><script type="text/template">## Hidden Confounds

![CT Scan Image](radiology-scan.jpg)
<!-- .element: class="plain stretch" -->


<aside class="notes"><p>ML algorithms may pick up on things that do not relate to the task but correlate with the outcome or hidden human inputs. For example, in cancer prediction, ML models have picked up on the kind of scanner used, learning that mobile scanners were used for particularly sick patients who could not be moved to the large installed scanners in a different part of the hospital.</p>
</aside></script></section><section data-markdown><script type="text/template">## Reverse Causality

![Chess](chess.jpg)

<aside class="notes"><p>(from Prediction Machines, Chapter 6) Early 1980s chess  program learned from Grandmaster games, learned that sacrificing queen would be a winning move, because it was occuring frequently in winning games. Program then started to sacrifice queen early.</p>
</aside></script></section><section data-markdown><script type="text/template">## Reverse Causality

![Hotel reception](hotel.jpg)

<aside class="notes"><p>(from Prediction Machines, Chapter 6) Low hotel prices in low sales season. Model might predict that high prices lead to higher demand.</p>
</aside></script></section><section data-markdown><script type="text/template">## Missing Counterfactuals

![Stock trading](stocktrading.jpg)

<aside class="notes"><p>Training data often does not indicate what would have happened with different situations, thus identifying causation is hard</p>
</aside></script></section><section data-markdown><script type="text/template">## Other Issues

* Insufficient training data
* Noisy training data
* Biased training data
* Overfitting
* Poor model fit, poor model selection, poor hyperparameters
* Missing context, missing important features
* Noisy inputs
* "Out of distribution" inputs

</script></section><section data-markdown><script type="text/template">## Mistakes are usually not random

Unlike physical processes -- e.g. probability of steel axle breaking

Model fails repeatedly for same input

Independent models may make same mistake

Systematic problems possible, e.g., fairness bias

Attackers can induce mistakes (adversarial inputs)

</script></section><section data-markdown><script type="text/template">## ML Models make Crazy Mistakes

Humans often make predicable mistakes
  * most mistakes near to correct answer, distribution of mistakes

ML models may be wildly wrong when they are wrong
   - especially black box models may use (spurious) correlations humans would never think about
   - may be very confident about wrong answer
   - "fixing" one mistake may cause others

</script></section><section data-markdown><script type="text/template">## Reasons barely matter

No model is every "correct"

Some mistakes are unavoidable

Anticipate the eventual mistake
* Make the system safe despite mistakes
* Consider the rest of the system (software + environment)
* Example: Thermal fuse in smart toaster

**ML model = unreliable component**
















</script></section></section><section ><section data-markdown><script type="text/template"># Designing for Mistakes

</script></section><section data-markdown><script type="text/template">## Bollards mitigate mistakes

<div class="tweet" data-src="https://twitter.com/WorldBollard/status/1542959589276192770"></div>
</script></section><section data-markdown><script type="text/template">## Bollards mitigate mistakes
<div class="tweet" data-src="https://twitter.com/WorldBollard/status/1550067808742031361"></div>
</script></section><section data-markdown><script type="text/template">## Bollards mitigate mistakes

<div class="tweet" data-src="https://twitter.com/WorldBollard/status/1534901378983796736"></div>


</script></section><section data-markdown><script type="text/template">## Many different strategies

Based on *fault-tolerant design*, assuming that there will be software/ML mistakes or environment changes violating assumptions

We will cover today:
* Human in the loop
* Undoable actions
* Guardrails
* Mistake detection and recovery (monitoring, doer-checker, fail-over, redundancy)
* Containment and isolation


</script></section><section data-markdown><script type="text/template">## Today's Running Example: Autonomous Train

<!-- colstart -->

![Docklands train](dlr.jpg)
<!-- .element: class="stretch" -->

<div class="small">CC BY 2.0 by Matt Brown</div>

<!-- col -->
* REQ: The train shall not collide with obstacles
* REQ: The train shall not depart until all doors are closed
* REQ: The train shall not trap people between the doors
* ...

<!-- colend -->

<aside class="notes"><p>The Docklands Light Railway system in London has operated trains without a driver since 1987. Many modern public transportation systems use increasingly sophisticated automation, including the Paris M√©tro Line 14 and the Copenhagen Metro</p>
</aside></script></section><section data-markdown><script type="text/template">## Human-AI Interaction Design (Human in the Loop)


Recall:

* Automate
* Prompt
* Organize, annotate, or augment

</script></section><section data-markdown><script type="text/template">## Human in the Loop

* AI and humans are good at predictions in different settings
  * AI better at statistics at scale and many factors
  * Humans understand context and data generation process; often better with thin data 
* AI for prediction, human for judgment?
* But be aware of:
  * Notification fatigue, complacency, just following predictions; see *Tesla autopilot*
  * Compliance/liability protection only?
* Deciding when and how to interact
* Lots of UI design and HCI problems

<aside class="notes"><p>Cancer prediction, sentencing + recidivism, Tesla autopilot, military &quot;kill&quot; decisions, powerpoint design suggestions</p>
</aside></script></section><section data-markdown><script type="text/template">## Human in the Loop - Examples

* Email response suggestions

![Example of email responses suggested by GMail](email.png)

* Fall detection smartwatch
* Safe browsing
</script></section><section data-markdown><script type="text/template">## Human in the Loop - Examples?

![Docklands train](dlr.jpg)
<!-- .element: class="stretch" -->

<!-- references_ -->

CC BY 2.0 by Matt Brown
</script></section><section data-markdown><script type="text/template">## Undoable actions

* Automating only actions that can be undone
* Design system to make actions undoable
* Designing a process to appeal decisions

**Examples?**
</script></section><section data-markdown><script type="text/template">## Undoable actions - Examples

![Nest thermostat](nest.jpg)
<!-- .element: class="stretch" -->

* Override thermostat setting
* Undo slide design suggestions
* Automated shipment + offering free return shipment
* Appeal process for banned "spammers" or "bots"
* Easy to repair bumpers on autonomous vehicles?

<!-- img: https://unsplash.com/photos/RFAHj4tI37Y -->

</script></section><section data-markdown><script type="text/template">## Undoable actions - Examples?

![Docklands train](dlr.jpg)
<!-- .element: class="stretch" -->

<!-- references_ -->

CC BY 2.0 by Matt Brown
</script></section><section data-markdown><script type="text/template">## Guardrails

* Further process predictions before taking actions
* Limit model predictions to safe ranges
* Manual overrides for certain values
* Backup models for known problematic conditions
* Hardware protections

Ensures safe operation parameters despite wrong model predictions (without having to detect mistakes)
</script></section><section data-markdown><script type="text/template">## Guardrails - Examples

Recall: Thermal fuse in smart toaster

![Thermal fuse](thermalfuse.png)
<!-- .element: class="stretch" -->


+ maximum toasting time + extra heat sensor

</script></section><section data-markdown><script type="text/template">## Guardrails

![Example of email responses suggested by GMail](email.png)

**What guardrails may be appropriate?**

</script></section><section data-markdown><script type="text/template">## Guardrails - Examples?

![Docklands train](dlr.jpg)
<!-- .element: class="stretch" -->

<!-- references_ -->

CC BY 2.0 by Matt Brown
</script></section><section data-markdown><script type="text/template">## Guardrails - Examples

![Metro station Cour Saint-√âmilion in Paris with automated platform screen doors that only open when a train is in the station](platformdoors.png)
<!-- .element: class="stretch" -->

<!-- references_ -->

CC BY-SA 4.0 by Chabe01

</script></section><section data-markdown><script type="text/template">## Mistake detection and recovery

Design recovery mechanism if mistakes are detectable, directly or indirectly

Requires detection mechanism (external monitor, redundancy) and response

![](doer-checker.jpg)
<!-- .element: class="stretch" -->


</script></section><section data-markdown><script type="text/template">## Mistake detection

Independent mechanism to detect problems (in the real world)


Example: Gyrosensor to detect a train taking a turn too fast

![Train taking a corner](traincorner.jpg)
<!-- .element: class="stretch" -->


</script></section><section data-markdown><script type="text/template">## Mistake detection -- many strategies

* Detect sensor failures with diagnostics
* Detect sensor failures with redundancies
* Monitor software for crashes
* Monitor for expected operation parameters
  - e.g., proper lighting of security camera footage
* Sense expected outcomes of actions
  - e.g., Vehicle accelerating, human clicking on something

**Examples in autonomous train scenario?**

<aside class="notes"><p>Independent sensor: Vision system sees no obstacle, but door sensor reports resistance</p>
<p>Redundant sensor: Two cameras report significantly different images</p>
<p>Broken sensor: No image, black image, white noise from camera</p>
</aside></script></section><section data-markdown><script type="text/template">## Doer-Checker Example: AV

<!-- colstart -->

![](safety-controller.jpg)
<!-- .element: class="stretch" -->

<!-- col -->

<div class="smallish">

* ML-based controller (doer): Generate commands to steer the vehicle
  * Complex DNN; makes performance-optimal control decisions
* Safety controller (checker): Checks commands from ML controller; overrides it
  with a safe default command if the ML action is risky
  * Simpler, based on verifiable, transparent logic; conservative control

</div>

<!-- colend --></script></section><section data-markdown><script type="text/template">## Doer-Checker Example: AV

![](safety-controller-scenario.png)
<!-- .element: class="stretch" -->


* Yellow region: Slippery road, causes loss of traction; unexpected 
* Checker: Monitor detects lane departure, overrides with safe steering commands

<!-- references_ -->
_Runtime-Safety-Guided Policy Repair_, Intl. Conference on Runtime Verification (2020)
</script></section><section data-markdown><script type="text/template">## Graceful Degradation (Fail-safe)

<video>
    <source data-src="rc-car.mp4" type="video/mp4" />
</video>

* Goal: When a component failure is detected, achieve system 
  safety by reducing functionality and performance
* Switches operating mode when failure detected (e.g., slower, conservative)
</script></section><section data-markdown><script type="text/template">## Redundancy

Useful for problem detection *and* response
* Redundant sensors
* Redundant models/subsystems
  - Hot Standby: Standby watches & takes over when primary fails
  - Voting: Select the majority decision

![](redundancy.jpg)
<!-- .element: class="stretch" -->

But: Software + models rarely really independent

</script></section><section data-markdown><script type="text/template">## Redundancy Example: Sensor Fusion

![](sensor-fusion.jpeg)
<!-- .element: class="stretch" -->

* Combine data from a wide range of sensors
* Provides partial information even when some sensor is faulty
* A critical part of modern self-driving vehicles


</script></section><section data-markdown><script type="text/template">## Containment: Decoupling & Isolation

**Design principle**: Faults in a low-critical (LC) components should not impact
  high-critical (HC) components


Example: Do not connect fly-by-wire software with plane's entertainment system

**Example in autonomous train?**
</script></section><section data-markdown><script type="text/template">## Poor Decoupling: USS Yorktown (1997)

![](yorktown.png)
<!-- .element: class="stretch" -->

* Invalid data entered into DB; divide-by-zero crashes entire network
* Required rebooting the whole system; ship dead in water for 3h
* Lesson: Handle expected component faults; prevent propagation
</script></section><section data-markdown><script type="text/template">## Poor Decoupling: Automotive Security

![](invehicle.png)
<!-- .element: class="stretch" -->

* Main components connected through a common CAN bus
  * Broadcast; no access control (anyone can read/write)
* Can control brake/engine by playing a malicious MP3

<!-- references_ -->
_Experimental Security Analysis of a Modern Automobile_, Koscher et al., (2010)
</script></section><section data-markdown><script type="text/template">## Containment: Decoupling & Isolation

* **Design principle**: Faults in a low-critical (LC) components should not impact
high-critical (HC) components
* Apply the principle of *least privilege*
  * LC components should have minimal necessary access
* Limit interactions across criticality boundaries
  * Deploy LC & HC components on different networks
  * Add monitors/checks at interfaces
* Is an ML component in my system performing an LC or HC task?
  * If HC, can we "demote" it into LC?
  * Alternatively, if possible, replace/augment HC ML components with
  non-ML ones
</script></section><section data-markdown><script type="text/template">## Design Strategies Summary

Human in the loop

Undoable actions

Guardrails

Mistake detection and recovery (monitoring, doer-checker, fail-over, redundancy)

Containment and isolation
</script></section><section data-markdown><script type="text/template">## Short Breakout

What design strategies would you consider to mitigate ML mistakes:
* Credit card fraud detection
* Speed limiter for cars (with vision system to detect traffic signs)

Consider: Human in the loop, Undoable actions, Guardrails, Mistake detection and recovery (monitoring, doer-checker, fail-over, redundancy), Containment and isolation


As a group, post one design idea for each scenario to `#lecture` and tag all group members.







</script></section></section><section ><section data-markdown><script type="text/template"># Risk Analysis


</script></section><section data-markdown><script type="text/template">## What's the worst that could happen?

![Robot uprising](robot-uprising.jpg)<!-- .element: style="width:800px" -->

<!-- references -->

*Likely?* Toby Ord predicts existential risk from GAI at 10% within 100 years:
Toby Ord, "The Precipice: Existential Risk and the Future of Humanity", 2020

<aside class="notes"><p>Discussion on existential risk. Toby Ord, Oxford philosopher predicts</p>
</aside></script></section><section data-markdown><script type="text/template">[![Paperclips game](paperclips.png)](https://www.decisionproblem.com/paperclips/index2.html)
<!-- .element: class="stretch" -->

</script></section><section data-markdown><script type="text/template">## What's the worst that could happen?

![Lane Assist in Tesla](lane.jpg)
<!-- .element: class="stretch" -->

</script></section><section data-markdown><script type="text/template">## What's the worst that could happen?

![Cancer detection](radiology-scan.jpg)
<!-- .element: class="stretch" -->

</script></section><section data-markdown><script type="text/template">## What's the worst that could happen?

![Tay Chat Bot deying Holocaust](tay.png)
<!-- .element: class="stretch" -->
</script></section><section data-markdown><script type="text/template">## What's the worst that could happen?

![Amazon Hiring Tool Scraped due to Bias](amazonhiring.png)
<!-- .element: class="stretch" -->


</script></section><section data-markdown><script type="text/template">## What is Risk Analysis?

What can possibly go wrong in my system, and what are potential 
impacts on system requirements?

Risk = Likelihood * Impact

A number of methods:
  * Failure mode & effects analysis (FMEA)
  * Hazard analysis
  * Why-because analysis
  * Fault tree analysis (FTA)
  * ...

</script></section></section><section ><section data-markdown><script type="text/template"># Fault Tree Analysis
</script></section><section data-markdown><script type="text/template">## Fault Tree Analysis (FTA)

<!-- colstart -->

<div class="small">

* Fault tree: A top-down diagram that displays the relationships
between a system failure (i.e., requirement violation) and its potential causes.  
  * Identify sequences of events that result in a failure
  * Prioritize the contributors leading to the failure
  * Inform decisions about how to (re-)design the system
  * Investigate an accident & identify the root cause 
* Often used for safety & reliability, but can also be used for
other types of requirements (e.g., poor performance, security attacks...)

</div>

<!-- col -->

![fta-sample](fta-sample.png)<!-- .element: style="width:400px" -->

<!-- colend --></script></section><section data-markdown><script type="text/template">## Fault Tree Analysis & ML

* ML is increaseingly used in safety-critical domains such as automotive, aeronautics, industrial control systems, etc.,
* ML models are just one part of the system
* ML models will EVENTUALLY make mistakes
  * Output wrong predictions/values
  * Fail to adapt to the changing environment
  * Confuse users, etc.,
* How do mistakes made by ML contribute to system failures? How do we
  ensure their mistakes do not result in a catastrophic outcome?
</script></section><section data-markdown><script type="text/template">## Fault Trees: Basic Building Blocks

![fta-blocks](fta-blocks.png)
<!-- .element: class="stretch" -->

Event: An occurrence of a fault or an undesirable action
  * (Intermediate) Event: Explained in terms of other events
  * Basic Event: No further development or breakdown; leaf

Gate: Logical relationship between an event & its immedicate subevents
  * AND: All of the sub-events must take place
  * OR: Any one of the sub-events may result in the parent event

</script></section><section data-markdown><script type="text/template">## Fault Tree Example

![fta-example](fta-example.png)
<!-- .element: class="stretch" -->


* Every tree begins with a TOP event (typically a violation of a requirement)
* Every branch of the tree must terminate with a basic event

<!-- references_ -->
Figure from _Fault Tree Analysis and Reliability Block Diagram_
(2016), Jaroslav Menƒç√≠k. 
</script></section><section data-markdown><script type="text/template">## Analysis: What can we do with fault trees?

1. Qualitative analysis: Determine potential root causes of a
    failiure through _minimal cut set analysis_

2. Quantitative analysis: Compute the probablity of a failure
</script></section><section data-markdown><script type="text/template">## Minimal Cut Set Analysis

<!-- colstart -->

*Cut set:* A set of basic events whose simultaneous occurrence is
  sufficient to guarantee that the TOP event occurs.

*Minimal cut set:* A cut set from which a smaller cut set can't be
obtained by removing a basic event.


<!-- col -->


![fta-example](fta-example.png)
<!-- .element: class="stretch" -->

**What are minimal cut sets here?**

<!-- colend -->


</script></section><section data-markdown><script type="text/template">## Failure Probability Analysis

To compute the probability of the top event:
  * Assign probabilities to basic events (based on domain knowledge)
  * Apply probability theory to compute probabilities of intermediate events
	through AND & OR gates
  * (Alternatively, as sum of prob. of minimal cut sets) 

In this class, we won't ask you to do this.
  * Why is this especially challenging for software? 
</script></section><section data-markdown><script type="text/template">## FTA Process

<div class="smallish">

1. Specify the system structure
   * Environment entities & machine components
   * Assumptions (ASM) & specifications (SPEC)
2. Identify the top event as a requirement violation (REQ)
3. Construct the fault tree
	* Derive intermediate events from a violation of ENV or SPEC
	* Decompose the intermediate events further down based on the knowledge of the domain or components
4. Analyze the tree, Identify all possible minimal cut sets
5. Consider design modifications
   * Eliminate certain cutsets, or
   * Increase the size of min cutsets
6. Repeat

</div>
</script></section><section data-markdown><script type="text/template">## Example: Autonomous Train

![Docklands train](dlr.jpg)
<!-- .element: class="stretch" -->

<!-- references_ -->

CC BY 2.0 by Matt Brown

<aside class="notes"><p>The Docklands Light Railway system in London has operated trains without a driver since 1987. Many modern public transportation systems use increasingly sophisticated automation, including the Paris M√©tro Line 14 and the Copenhagen Metro</p>
</aside></script></section><section data-markdown><script type="text/template">## Example: Autonomous Train


* REQ: The train shall not depart until all doors are closed
* REQ: The train shall not trap people between the doors

Solution combines a vision-based system identifying people in the door with pressure sensors and a manual override.

**Using a fault tree identify possible problems that could lead to *trapping a person in the door*.**
  * Hint: What assumptions and specifications might be violated?
</script></section><section data-markdown><script type="text/template">![FTA for trapping people in doors of a train](fta.svg)
</script></section><section data-markdown><script type="text/template">## Consider Mitigations

* Remove basic events with mitigations
* Increase the size of cut sets with mitigations


![FTA for trapping people in doors of a train](fta-without-mitigation.svg)
<!-- .element: class="stretch" -->
</script></section><section data-markdown><script type="text/template">![Updated FTA for trapping people in doors of a train](fta-mitigation.svg)

</script></section><section data-markdown><script type="text/template">## One more example: FTA for Lane Assist

<div class="smaller">

* REQ: The vehicle must be prevented from veering off the lane.
* SPEC: Lane detector accurately identifies lane markings in the input image; 
  the controller generates correct steering commands
* ENV: Sensors are providing accurate information about the lane;
  driver responses when given warning; steering wheel is functional

</div>

![lane-assist-fta](lane-assist-fta.png)
<!-- .element: class="stretch" -->
</script></section><section data-markdown><script type="text/template">## Practice FTA

In recitation on Friday!

In homework I2.

Several examples in past midterms.
</script></section><section data-markdown><script type="text/template">## FTA: Caveats

In general, building a **complete** tree is impossible
  * There are probably some faulty events that you missed
  * "Unknown unknowns"

Domain knowledge is crucial for improving coverage
  * Talk to domain experts; augment your tree as you learn more

FTA is still very valuable for risk reduction!
  * Forces you to think about & explictly document possible failure scenarios
  * A good starting basis for designing mitigations

















</script></section></section><section ><section data-markdown><script type="text/template"># FMEA


</script></section><section data-markdown><script type="text/template">## Fault-Tree Analysis Discussion

* Town-down, *backward* search for the root cause of issues
    - from final outcomes to initiating events
* Issues (TOP events) need to be known upfront
* Quantitative analysis possible
* Useful for understanding faults post-hoc
* Where do outcomes come from?
</script></section><section data-markdown><script type="text/template">## Failure Mode and Effects Analysis (FMEA)

![](fmea-radiation.png)
<!-- .element: class="stretch" -->

* A __forward search__ technique to identify potential hazards
* Widely used in aeronautics, automotive, healthcare, food services,
  semiconductor processing, and (to some extent) software
</script></section><section data-markdown><script type="text/template">## FMEA Process

(a) Identify system components

(b) Enumerate potential failure modes
  * *for ML component: Always suspect prediction may be wrong*

(c) For each failure mode, identify:
  * Potential hazardous effect on the system
  * Method for detecting the failure
  * Potential mitigation strategy


</script></section><section data-markdown><script type="text/template">## FMEA Example: Autonomous Train Doors


<!-- discussion -->

Failure modes? Failure effects? Detection? Mitigation?


</script></section><section data-markdown><script type="text/template">## Exercise: FMEA Analysis for Smart Toaster

(video sensor, temperature sensor, heat sensor, user setting, ML model, heuristic shutdown, thermal fuse)


Failure modes? Failure effects? Detection? Mitigation?

<!-- discussion -->

</script></section><section data-markdown><script type="text/template">## FMEA Excerpt: Autonomous Car

![FMEA for autonomous car](fmea-car.png)

<!-- references -->

Excerpt of an FMEA table for analyzing components in an autonomous vehicle, from üóé David Robert Beachum. Methods for assessing the safety of autonomous vehicles. University of Texas Theses and Dissertations (2019).
</script></section><section data-markdown><script type="text/template">## "Wrong Prediction" as Failure Mode?

"Wrong prediction" is a very cause grained failure mode of every model

May not be possible to decompose further

However, may evaluate causes of wrong prediction for better understanding, as far as possible --> FTA?



</script></section><section data-markdown><script type="text/template">## FMEA Summary

Forward analysis: From components to possible failures

Focus on single component failures, no interactions

Identifying failure modes may require domain understanding


</script></section></section><section ><section data-markdown><script type="text/template"># HAZOP

</script></section><section data-markdown><script type="text/template">## Hazard and Interoperability Study (HAZOP)
   
*identify hazards and component fault scenarios through guided inspection of requirements*

![HAZOP example](hazop-perception.jpg)

</script></section><section data-markdown><script type="text/template">## Hazard and Operability Study (HAZOP)

<!-- colstart -->

A __forward search__ method to identify potential hazards

For each component, use a set of __guide words__ to generate
possible deviations from expected behavior

Consider the impact of each generated deviation: Can it  result in a system-level hazard?

<!-- col -->

![](hazop.png)


<!-- colend -->

</script></section><section data-markdown><script type="text/template">## HAZOP & ML

In addition to traditional analysis:
Analyze possible mistakes of all ML components

Original guidewords:
NO OR NOT,
MORE,
LESS,
AS WELL AS,
PART OF,
REVERSE,
OTHER THAN / INSTEAD,
EARLY,
LATE,
BEFORE,
AFTER


Additional ML-specific guidewords: WRONG, INVALID, INCOMPLETE, PERTURBED, and INCAPABLE.


</script></section><section data-markdown><script type="text/template">## HAZOP Example: Emergency Braking (EB)

<!-- colstart -->

<div class="small">

Specification: EB must apply a maximum braking command to the engine.

  * __NO OR NOT__: EB does not generate any braking command.
  * __LESS__: EB applies less than max. braking.
  * __LATE__: EB applies max. braking but after a delay of 2
  seconds.
  * __REVERSE__: EB generates an acceleration command instead of braking.
  * __BEFORE__: EB applies max. braking before a possible crash is detected.

</div>

<!-- col -->

![](hazop-eb.jpg)

<!-- colend -->
</script></section><section data-markdown><script type="text/template">## Breakout: Automated Train Doors

Analyze the vision component to detect obstacles in train doors

NO OR NOT,
MORE,
LESS,
AS WELL AS,
PART OF,
REVERSE,
OTHER THAN / INSTEAD,
EARLY,
LATE,
BEFORE,
AFTER, WRONG, INVALID, INCOMPLETE, PERTURBED, and INCAPABLE.


Using HAZOP: As a group answer in `#lecture`, tagging group members:

>  * What is the specification of the perception component? 
>  * What are possible deviations from the specification?
>  * What are potential hazards resulting from these deviations?

</script></section><section data-markdown><script type="text/template">## HAZOP: Benefits & Limitations

* Easy to use; encourages systematic reasoning about component faults
* Can be combined with FTA/FMEA to generate faults (i.e., basic
events in FTA)
* Potentially labor-intensive; relies on engineer's judgement
* Does not guarantee to find all hazards (but also true for other techniques)
</script></section><section data-markdown><script type="text/template">## Remarks: Hazard Analysis

None of these methods guarantee completeness
  * You may still be missing important hazards, failure modes

Intended as structured approaches to thinking about failures
  * But cannot replace human expertise and experience














</script></section></section><section  data-markdown><script type="text/template"># Summary

* Accept that a failure is inevitable
  * ML components will eventually make mistakes, reasons barely matter
  * Environment may evolve over time, violating assumptions
* Design strategies for mitigating mistakes
  * Human in the loop, Undoable actions, Guardrails, Mistake detection and recovery (monitoring, doer-checker, fail-over, redundancy), Containment and isolation
* Use risk analysis to identify and mitigate potential problems
  - FTA, FMEA, HAZOP
</script></section></div>
    </div>

    <script src="./../dist/reveal.js"></script>

    <script src="./../_assets/mymarkdown.js"></script>
    <script src="./../plugin/markdown/markdown.js"></script>
    <script src="./../plugin/highlight/highlight.js"></script>
    <script src="./../plugin/zoom/zoom.js"></script>
    <script src="./../plugin/notes/notes.js"></script>
    <script src="./../plugin/math/math.js"></script>

    <script src="./../node_modules/reveal.js-menu/menu.js"></script>
    <script src="./../node_modules/reveal.js-plugins/embed-tweet/plugin.js"></script>


    <script>
      function extend() {
        var target = {};
        for (var i = 0; i < arguments.length; i++) {
          var source = arguments[i];
          for (var key in source) {
            if (source.hasOwnProperty(key)) {
              target[key] = source[key];
            }
          }
        }
        return target;
      }

      // default options to init reveal.js
      var defaultOptions = {
        controls: true,
        progress: true,
        history: true,
        center: true,
        transition: 'default', // none/fade/slide/convex/concave/zoom
        controls: true,
        slideNumber: true,
        markdown: {
          renderer: patchMarkdown(RevealMarkdown().marked)
        },
        plugins: [
          RevealMarkdown,
          RevealHighlight,
          RevealZoom,
          RevealNotes,
          RevealMath,
          RevealMenu,
          RevealEmbedTweet
        ]
      };

      // options from URL query string
      var queryOptions = Reveal().getQueryHash() || {};

      var options = extend(defaultOptions, {"controls":true,"progress":true,"theme":"white","slideNumber":true,"hash":true,"history":false,"center":false,"width":1280,"height":720,"margin":0.1,"transition":"none"}, queryOptions);
    </script>


    <script>
      Reveal.initialize(options);
    </script>
  </body>
</html>